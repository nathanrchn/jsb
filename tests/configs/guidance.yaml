model_engine_config:
  model: "bartowski/Meta-Llama-3.1-8B-Instruct-GGUF"
  filename: "*Q8_0.gguf"
  temperature: 0.0
max_tokens: 2048