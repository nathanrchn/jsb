model_engine_config:
  model: "bartowski/Llama-3.2-1B-Instruct-GGUF"
  filename: "*Q8_0.gguf"
  temperature: 0.0
hf_tokenizer_id: "meta-llama/Llama-3.2-1B-Instruct"
max_tokens: 2048
